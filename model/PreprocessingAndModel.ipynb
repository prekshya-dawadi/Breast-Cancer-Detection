{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 227\n",
    "epochs = 50\n",
    "train_path = os.path.normpath(\"D:\\Projects\\DL\\BCC\\dataset\\Train\")\n",
    "test_path = os.path.normpath(\"D:\\Projects\\DL\\BCC\\dataset\\Test\")\n",
    "batch_size = 32\n",
    "seed = 40\n",
    "color_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2233 files belonging to 2 classes.\n",
      "Using 1787 files for training.\n",
      "Found 2233 files belonging to 2 classes.\n",
      "Using 446 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Data stored in the form of tensors\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels = \"inferred\",\n",
    "    label_mode = \"int\",\n",
    "    validation_split = 0.2,\n",
    "    subset = \"training\",\n",
    "    seed = seed,\n",
    "    image_size = (image_size,image_size),\n",
    "    batch_size = batch_size,\n",
    ")\n",
    "\n",
    "val_ds = image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels = \"inferred\",\n",
    "    label_mode = \"int\",\n",
    "    validation_split = 0.2,\n",
    "    subset = \"validation\",\n",
    "    seed = seed,\n",
    "    image_size = (image_size,image_size),\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 638 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = image_dataset_from_directory(\n",
    "    test_path,\n",
    "    labels = \"inferred\",\n",
    "    label_mode = \"int\",\n",
    "    seed = seed,\n",
    "    image_size = (image_size,image_size),\n",
    "    batch_size = batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel crashes when attempting to display some of the images using matplotlib\n",
    "# Just for displaying some images with their labels\n",
    "# plt.figure(figsize = (10, 10))\n",
    "# class_names = train_ds.class_names\n",
    "# for images, labels in train_ds.take(1):\n",
    "#     class_labels = [class_names[label] for label in labels.numpy()]\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i+1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_labels[i])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to numpy form\n",
    "train_images, train_labels, val_images, val_labels = [], [], [], []\n",
    "\n",
    "for images, labels in train_ds:\n",
    "    train_images.append(images)\n",
    "    train_labels.append(labels)\n",
    "\n",
    "train_images = np.vstack(train_images)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    val_images.append(images)\n",
    "    val_labels.append(labels)\n",
    "\n",
    "val_images = np.vstack(val_images)\n",
    "val_labels = np.concatenate(val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = [], []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    test_images.append(images)\n",
    "    test_labels.append(labels)\n",
    "\n",
    "test_images = np.vstack(test_images)\n",
    "test_labels = np.concatenate(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1787,)\n",
      "(1787, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_augmentation = ImageDataGenerator(\n",
    "    rotation_range = 40, # Randomly rotate up to 40 degrees\n",
    "    width_shift_range = 0.2, # Randomly shift width up to 20%\n",
    "    height_shift_range = 0.2, # Randomly shift width up to 20%\n",
    "    shear_range = 0.2, #shear transformations\n",
    "    zoom_range = 0.2, # zoom in or out up to 20%\n",
    "    horizontal_flip = True, # Randomly flip images horizontally\n",
    "    fill_mode = 'nearest', # how to fill in newly created pixels\n",
    "    featurewise_center = True,\n",
    "    featurewise_std_normalization = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_augmentation.fit(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_augmented = image_augmentation.flow(\n",
    "train_images, train_labels, batch_size = batch_size)\n",
    "val_augmented = image_augmentation.flow(val_images, val_labels, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation=\"relu\", input_shape=(image_size, image_size, 3)))  # Adjust input shape\n",
    "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 225, 225, 16)      448       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 223, 223, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 86528)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                5537856   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5635361 (21.50 MB)\n",
      "Trainable params: 5635361 (21.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_images) // batch_size\n",
    "valid_steps = len(val_images) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "55/55 [==============================] - 156s 3s/step - loss: 0.8096 - accuracy: 0.4957 - val_loss: 0.6933 - val_accuracy: 0.4736\n",
      "Epoch 2/50\n",
      "55/55 [==============================] - 151s 3s/step - loss: 0.6931 - accuracy: 0.5060 - val_loss: 0.6936 - val_accuracy: 0.4712\n",
      "Epoch 3/50\n",
      "33/55 [=================>............] - ETA: 54s - loss: 0.6928 - accuracy: 0.5157"
     ]
    }
   ],
   "source": [
    "model.fit(train_augmented, steps_per_epoch=train_steps, validation_data=val_augmented, validation_steps=valid_steps, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_images, test_labels, batch_size=batch_size)\n",
    "print( 'Loss = {} and Accuracy = {} %'.format( results[0] , results[1] * 100 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End for now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
